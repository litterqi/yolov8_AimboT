[论文](https://github.com/litterqi/yolov8_AimboT/blob/main/%E4%BF%AE%E6%94%B9%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/ShuffleNetV2/ShuffleNetV2.pdf)

![image](https://github.com/litterqi/yolov8_AimboT/assets/123362884/442ae9ab-dfe4-4c45-821f-a7f34eeac7a1)

论文指出用间接指标FLOPs来衡量模型架构速度是不全面的。在两个硬件平台上测量四种网络结构的准确性（验证集上的ImageNet分类）、速度和FLOPs，性能最好的算法，即ShuffleNetv2都在右上角的区域。

![image](https://github.com/litterqi/yolov8_AimboT/assets/123362884/05aa4b25-8cb6-45f8-9166-2a81350e9dd8)

将整体运行时间被分解为不同的操作。注意到FLOPs指标只考虑了卷积部分。虽然这部分消耗了大部分时间，但其他操作包括数据输入/输出、数据shuffle等也占用了大量时间。只用FLOPs对实际运行时间的估计不够准确。

针对以上问题，该论文对网络结构进行了设计：

![image](https://github.com/litterqi/yolov8_AimboT/assets/123362884/6877a779-b7b5-46ef-94e5-0307dbb615b3)

输入层

Image：输入图像的大小为224×224，通道数为3。


卷积层和池化层

Conv1：第一个卷积层，输出尺寸为112×112，卷积核大小为3×3，步长为2，输出通道数为24，不同缩放系数下输出通道数不变。

MaxPool：最大池化层，输出尺寸为56×56，池化核大小为3×3，步长为2。


Stage2

输出尺寸为28×28，卷积核大小为3×3，步长为2，重复次数为1，输出通道数在不同缩放系数下分别为48（0.5×），116（1×），176（1.5×），244（2×）。


Stage3

输出尺寸为14×14，卷积核大小为3×3，步长为2，重复次数为7，输出通道数在不同缩放系数下分别为96（0.5×），232（1×），352（1.5×），488（2×）。


Stage4

输出尺寸为7×7，卷积核大小为3×3，步长为2，重复次数为3，输出通道数在不同缩放系数下分别为192（0.5×），464（1×），704（1.5×），976（2×）。


Conv5

输出尺寸为7×7，卷积核大小为1×1，步长为1，重复次数为1，输出通道数在不同缩放系数下分别为1024（0.5×, 1×, 1.5×），2048（2×）。


全局池化层和全连接层

GlobalPool：全局池化层，输出尺寸为1×1，池化核大小为7×7。

FC：全连接层，输出通道数为1000，不同缩放系数下输出通道数不变。


FLOPs 和权重数量

FLOPs：计算量在不同缩放系数下分别为41M（0.5×），146M（1×），299M（1.5×），591M（2×）。
